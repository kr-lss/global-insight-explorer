"""
Content extractors for different media types
"""
from abc import ABC, abstractmethod
import requests
from bs4 import BeautifulSoup
from youtube_transcript_api import YouTubeTranscriptApi

from app.config import config


class BaseExtractor(ABC):
    """ì½˜í…ì¸  ì¶”ì¶œê¸° ê¸°ë³¸ í´ë˜ìŠ¤"""

    @abstractmethod
    def extract(self, url: str) -> str:
        """URLì—ì„œ í…ìŠ¤íŠ¸ ì½˜í…ì¸ ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        pass


class YoutubeExtractor(BaseExtractor):
    """ìœ íŠœë¸Œ ìë§‰ ì¶”ì¶œ ì „ëµ (ìë§‰ ìš°ì„ , ì‹¤íŒ¨ ì‹œ Direct URL Processing)"""

    def __init__(self):
        """YouTube Video Service ì´ˆê¸°í™”"""
        self.video_service = None

        try:
            from app.utils.youtube_video_service import YouTubeVideoService
            self.video_service = YouTubeVideoService()
            print("âœ… (YoutubeExtractor) YouTube Video Service ì—°ê²° ì„±ê³µ")
        except Exception as e:
            print(f"âš ï¸ (YoutubeExtractor) YouTube Video Service ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def extract(self, url: str) -> str:
        """í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹: ìë§‰ ìš°ì„ , ì‹¤íŒ¨ ì‹œ Direct URL Processing"""

        # 1ë‹¨ê³„: ìë§‰ ì¶”ì¶œ ì‹œë„
        try:
            print("ğŸ“ ìë§‰ ì¶”ì¶œ ì‹œë„ ì¤‘...")
            transcript_text = self._extract_transcript(url)
            print(f"âœ… ìë§‰ ì¶”ì¶œ ì„±ê³µ: {len(transcript_text)} ê¸€ì")
            return transcript_text
        except Exception as transcript_error:
            print(f"âš ï¸ ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨: {transcript_error}")

            # 2ë‹¨ê³„: Direct URL Processingìœ¼ë¡œ ì˜ìƒ ë¶„ì„ (ë‹¤ìš´ë¡œë“œ ë¶ˆí•„ìš”)
            if self.video_service:
                print("ğŸ¬ Direct URL Processingìœ¼ë¡œ ì˜ìƒ ë¶„ì„ ì‹œë„ ì¤‘...")
                try:
                    result = self.video_service.analyze_video(url, analysis_type="transcript")

                    # transcript í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    transcript = result.get('transcript', '')
                    if transcript:
                        print(f"âœ… ì˜ìƒ ë¶„ì„ ì„±ê³µ: {len(transcript)} ê¸€ì")
                        return transcript
                    else:
                        raise Exception("ì˜ìƒ ë¶„ì„ ê²°ê³¼ì— transcriptê°€ ì—†ìŠµë‹ˆë‹¤")

                except Exception as video_error:
                    print(f"âŒ ì˜ìƒ ë¶„ì„ ì‹¤íŒ¨: {video_error}")
                    raise Exception(
                        f"ìë§‰ ì¶”ì¶œê³¼ ì˜ìƒ ë¶„ì„ ëª¨ë‘ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\n"
                        f"ìë§‰ ì˜¤ë¥˜: {transcript_error}\n"
                        f"ì˜ìƒ ë¶„ì„ ì˜¤ë¥˜: {video_error}"
                    )
            else:
                raise Exception(
                    f"ìë§‰ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìœ¼ë©°, YouTube Video Serviceë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                    f"ìë§‰ ì˜¤ë¥˜: {transcript_error}"
                )

    def _extract_transcript(self, url: str) -> str:
        """ìœ íŠœë¸Œ ìë§‰ ì¶”ì¶œ (ê¸°ì¡´ ë¡œì§)"""
        if 'v=' in url:
            video_id = url.split('v=')[1].split('&')[0]
        elif 'youtu.be/' in url:
            video_id = url.split('youtu.be/')[1].split('?')[0]
        else:
            raise ValueError("ìœ íš¨í•˜ì§€ ì•Šì€ ìœ íŠœë¸Œ URL")

        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)

        try:
            # 1. í•œêµ­ì–´ ìë§‰ ì‹œë„
            transcript = transcript_list.find_transcript(['ko'])
        except:
            # 2. ì˜ì–´ ìë§‰ ì‹œë„
            transcript = transcript_list.find_transcript(['en'])

        text = ' '.join([item['text'] for item in transcript.fetch()])
        return text


class ArticleExtractor(BaseExtractor):
    """ê¸°ì‚¬ ë³¸ë¬¸ ì¶”ì¶œ ì „ëµ"""

    def extract(self, url: str) -> str:
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            response = requests.get(url, headers=headers, timeout=15)
            response.raise_for_status()

            soup = BeautifulSoup(response.content, 'html.parser')

            # ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±°
            for tag in soup(
                ['script', 'style', 'nav', 'header', 'footer', 'aside', 'form']
            ):
                tag.decompose()

            # ê¸°ì‚¬ ë³¸ë¬¸ ìœ ë ¥ íƒœê·¸ íƒìƒ‰
            article = (
                soup.find('article')
                or soup.find('main')
                or soup.find(id='content')
                or soup.find(class_='content')
                or soup.body
            )

            if article:
                text = article.get_text(separator=' ', strip=True)
                # ì§€ë‚˜ì¹˜ê²Œ ê¸´ ê³µë°± ì œê±°
                text = ' '.join(text.split())
                return text
            else:
                return ""

        except requests.RequestException as e:
            print(f"âš ï¸ ê¸°ì‚¬ ìš”ì²­ ì‹¤íŒ¨: {e}")
            raise Exception(f"ê¸°ì‚¬ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. URLì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        except Exception as e:
            print(f"âš ï¸ ê¸°ì‚¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise Exception(f"ê¸°ì‚¬ ë‚´ìš©ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
