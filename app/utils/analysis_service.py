"""
ë¶„ì„ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ì²˜ë¦¬í•˜ëŠ” ì„œë¹„ìŠ¤ (Global Insight Explorer v2)
- í•œêµ­ì–´ ì‚¬ìš©ì ìµœì í™” (ì…ë ¥/ì¶œë ¥: í•œêµ­ì–´, ë‚´ë¶€ê²€ìƒ‰: ì˜ì–´)
- Google Search Grounding ì˜¤ë¥˜ ìˆ˜ì • ë° ìµœì í™”
"""
import os
import json
import hashlib
from datetime import datetime

import vertexai
from vertexai.generative_models import GenerativeModel, Tool, GoogleSearchRetrieval
from google.cloud import firestore
from google.api_core.exceptions import GoogleAPICallError

from app.models.extractor import BaseExtractor, YoutubeExtractor, ArticleExtractor
from app.models.media import get_media_credibility
from app.config import config

# --- ì´ˆê¸°í™” ---
gemini = None
try:
    vertexai.init(project=config.GCP_PROJECT, location=config.GCP_REGION)
    # 1ì°¨/2ì°¨ ë¶„ì„ìš© ì¼ë°˜ ëª¨ë¸ (ë¹„ìš© íš¨ìœ¨ì ì¸ Flash ëª¨ë¸ ê¶Œì¥)
    gemini = GenerativeModel('gemini-2.0-flash') 
    print("âœ… (Service) Gemini API ì—°ê²° ì„±ê³µ")
except Exception as e:
    print(f"âš ï¸ (Service) Gemini API ì—°ê²° ì‹¤íŒ¨: {e}")

db = None
try:
    db = firestore.Client(project=config.GCP_PROJECT)
    print("âœ… (Service) Firestore ì—°ê²° ì„±ê³µ")
except Exception as e:
    print(f"âš ï¸ (Service) Firestore ì—°ê²° ì‹¤íŒ¨: {e}")


class AnalysisService:
    def __init__(self):
        self.extractors = {
            'youtube': YoutubeExtractor(),
            'article': ArticleExtractor(),
        }

    def _get_extractor(self, input_type: str) -> BaseExtractor:
        extractor = self.extractors.get(input_type)
        if not extractor:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì…ë ¥ íƒ€ì…: {input_type}")
        return extractor

    # ==================================================================
    # 1ï¸âƒ£ 1ì°¨ ë¶„ì„ (Initial Analysis) - í•œêµ­ì–´ ì‚¬ìš©ì ìµœì í™”
    # ==================================================================
    def analyze_content(self, url: str, input_type: str):
        # ìºì‹œ í™•ì¸
        cached = self._get_cache(url)
        if cached:
            return cached, True

        # ì½˜í…ì¸  ì¶”ì¶œ
        print(f"ğŸ“¥ ì½˜í…ì¸  ì¶”ì¶œ ì¤‘: {url[:50]}...")
        extractor = self._get_extractor(input_type)
        content = extractor.extract(url)
        
        if not content or len(content) < 50:
            raise Exception("ì½˜í…ì¸ ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ê±°ë‚˜ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.")
            
        print(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {len(content)} ê¸€ì")

        # AI ë¶„ì„
        print("ğŸ¤– Geminië¡œ 1ì°¨ ë¶„ì„ ì¤‘ (í•œê¸€ ìš”ì•½ + ì˜ì–´ ê²€ìƒ‰ì–´ ìƒì„±)...")
        result = self._analyze_with_gemini_bridge(content)
        print("âœ… 1ì°¨ ë¶„ì„ ì™„ë£Œ")

        # ìºì‹œ ì €ì¥
        self._set_cache(url, result)
        return result, False

    def _analyze_with_gemini_bridge(self, content: str):
        """
        Gemini í”„ë¡¬í”„íŠ¸: í•œêµ­ì–´ ì…ë ¥ì„ ë°›ì•„ 'í•œêµ­ì–´ ìš”ì•½'ê³¼ 'ì˜ì–´ ê²€ìƒ‰ì–´'ë¥¼ ë™ì‹œ ìƒì„±
        """
        if not gemini:
            raise Exception("Gemini APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        content = content[:config.MAX_CONTENT_LENGTH_FIRST_ANALYSIS]

        prompt = f"""
        ë‹¹ì‹ ì€ êµ­ì œ ì •ì„¸ ë° ë¯¸ë””ì–´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
        ì£¼ì–´ì§„ í…ìŠ¤íŠ¸(ì˜ìƒ ìë§‰ ë˜ëŠ” ê¸°ì‚¬)ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.

        [ë¶„ì„ ëŒ€ìƒ í…ìŠ¤íŠ¸]
        {content}

        [í•„ìˆ˜ ìš”êµ¬ì‚¬í•­]
        1. **ì‚¬ìš©ìëŠ” í•œêµ­ì¸ì…ë‹ˆë‹¤.** ëª¨ë“  ì„¤ëª…ê³¼ ìš”ì•½ì€ ìì—°ìŠ¤ëŸ¬ìš´ **í•œêµ­ì–´**ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        2. **ê²€ìƒ‰ í‚¤ì›Œë“œ(search_keywords_en)**ëŠ” ë°˜ë“œì‹œ **ì˜ì–´(English)**ë¡œ ì‘ì„±í•˜ì„¸ìš”. 
           (ì´ìœ : ì „ ì„¸ê³„ ë‰´ìŠ¤(GDELT, Google) ê²€ìƒ‰ ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•¨)
        3. **ê´€ë ¨ êµ­ê°€(target_country_codes)**ëŠ” í•´ë‹¹ ì´ìŠˆì™€ ì´í•´ê´€ê³„ê°€ ìˆëŠ” êµ­ê°€ë“¤ì˜ **2ìë¦¬ ISO ì½”ë“œ**ë¡œ ì‘ì„±í•˜ì„¸ìš”.
           (ì˜ˆ: í•œêµ­='KR', ë¯¸êµ­='US', ì¤‘êµ­='CN', ë¶í•œ='KP', ëŸ¬ì‹œì•„='RU', ì¼ë³¸='JP')

        [ì¶œë ¥ í˜•ì‹ (JSON Only)]
        {{
          "title_kr": "ì½˜í…ì¸  ì œëª© ë˜ëŠ” ì£¼ì œ (í•œêµ­ì–´)",
          "summary_kr": "ì „ì²´ ë‚´ìš© ìš”ì•½ (í•œêµ­ì–´ 3ë¬¸ì¥ ë‚´ì™¸)",
          "topics": ["ì£¼ì œ1", "ì£¼ì œ2"], 
          "key_claims": [
            {{
              "claim_kr": "í•µì‹¬ ì£¼ì¥ 1 (í•œêµ­ì–´)",
              "search_keywords_en": ["keyword1", "keyword2", "specific term"],
              "target_country_codes": ["CN", "US"] // ì´ ì£¼ì¥ì— ëŒ€í•´ ì…ì¥ì„ í™•ì¸í•´ë´ì•¼ í•  êµ­ê°€ë“¤
            }},
            {{
              "claim_kr": "í•µì‹¬ ì£¼ì¥ 2 (í•œêµ­ì–´)",
              "search_keywords_en": ["keyword3", "keyword4"],
              "target_country_codes": ["RU", "UA"]
            }}
          ]
        }}

        JSON ì™¸ì— ë‹¤ë¥¸ ë§ì€ í•˜ì§€ ë§ˆì„¸ìš”.
        """

        try:
            response = gemini.generate_content(prompt)
            result_text = response.text.strip().replace('```json', '').replace('```', '').strip()
            return json.loads(result_text)
        except Exception as e:
            print(f"âŒ AI 1ì°¨ ë¶„ì„ ì‹¤íŒ¨: {e}")
            raise Exception(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    # ==================================================================
    # 2ï¸âƒ£ 2ì°¨ ë¶„ì„ (Find Sources) - ìˆ˜ì •ëœ ë¡œì§ ëŒ€ì‘
    # ==================================================================
    def find_sources_for_claims(
        self, url: str, input_type: str, selected_claims: list, search_keywords: list
    ):
        """
        ì„ íƒëœ ì£¼ì¥ì— ëŒ€í•œ êµì°¨ ê²€ì¦ (Google Search + GDELT ì˜ˆì •)
        """
        # ì›ë³¸ ì½˜í…ì¸  ë‹¤ì‹œ ì¶”ì¶œ (ì»¨í…ìŠ¤íŠ¸ìš©)
        extractor = self._get_extractor(input_type)
        original_content = extractor.extract(url)

        # 1. ê¸°ì‚¬ ê²€ìƒ‰ (ì˜ì–´ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰)
        # TODO: í–¥í›„ ì—¬ê¸°ì— GDELT ê²€ìƒ‰ ë¡œì§ì„ ë³‘í•©í•  ì˜ˆì • (Hybrid Search)
        articles = self._search_real_articles(search_keywords)

        # 2. AI ê²€ì¦ (í•œêµ­ì–´ë¡œ ê²°ê³¼ ë¦¬í¬íŠ¸)
        print("ğŸ¤– Geminië¡œ 2ì°¨ ë¶„ì„ (íŒ©íŠ¸ì²´í¬ & ê´€ì  ë¹„êµ) ì¤‘...")
        analysis_result = self._compare_perspectives_with_gemini(
            original_content, selected_claims, articles
        )
        print("âœ… 2ì°¨ ë¶„ì„ ì™„ë£Œ")

        return analysis_result, articles

    def _search_real_articles(self, keywords: list):
        """
        Gemini Google Search Grounding (ìµœì‹  SDK ë¬¸ë²• ì ìš©)
        """
        if not keywords:
            return []
            
        # í‚¤ì›Œë“œê°€ ë¦¬ìŠ¤íŠ¸ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ë“¤ì–´ì˜¬ ìˆ˜ ìˆìŒ (1ì°¨ ë¶„ì„ êµ¬ì¡° ë³€ê²½ ë•Œë¬¸)
        flat_keywords = []
        for k in keywords:
            if isinstance(k, list):
                flat_keywords.extend(k)
            else:
                flat_keywords.append(k)
        
        query = " ".join(flat_keywords[:7])  # ë„ˆë¬´ ê¸¸ë©´ ì˜ë¦¼, ìµœëŒ€ 7ë‹¨ì–´ ê¶Œì¥
        print(f"ğŸ” Google Search Grounding ê²€ìƒ‰: {query}")

        try:
            # âœ… [ìˆ˜ì •ë¨] ìµœì‹  Vertex AI SDK ë°©ì‹
            search_tool = Tool.from_google_search_retrieval(
                GoogleSearchRetrieval()
            )
            
            # ê²€ìƒ‰ìš© ëª¨ë¸ ë³„ë„ ì´ˆê¸°í™” (Grounding ë„êµ¬ í¬í•¨)
            model = GenerativeModel(
                'gemini-2.0-flash',
                tools=[search_tool]
            )
            
            # Groundingì„ ê°•ì œí•˜ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸
            prompt = f"Search for latest news articles about: {query}. Provide details."
            
            response = model.generate_content(prompt)
            
            # TODO: Grounding Metadataì—ì„œ ì‹¤ì œ URL ì¶”ì¶œ ë¡œì§ì„ ê°œì„ í•´ì•¼ í•¨.
            # í˜„ì¬ëŠ” Grounding APIì˜ íŠ¹ì„±ìƒ í…ìŠ¤íŠ¸ ìƒì„±ì— ì§‘ì¤‘ë˜ì–´ ìˆìœ¼ë¯€ë¡œ,
            # ì •í™•í•œ URL ë¦¬ìŠ¤íŠ¸ê°€ í•„ìš”í•˜ë©´ Custom Search JSON APIë¥¼ ë³‘í–‰í•˜ëŠ” ê²ƒì´ ì¢‹ìŒ.
            # ì¼ë‹¨ì€ êµ¬ì¡° ìœ ì§€ë¥¼ ìœ„í•´ ìƒ˜í”Œ ë°ì´í„°(Fallback) ë˜ëŠ” Geminiê°€ ìƒì„±í•œ í…ìŠ¤íŠ¸ ë‚´ ì •ë³´ë¥¼ í™œìš©
            
            print("âš ï¸ Google Search Grounding ì™„ë£Œ (URL ì¶”ì¶œ ë¡œì§ ë³´ì™„ í•„ìš”)")
            return self._get_sample_articles(flat_keywords) 

        except Exception as e:
            print(f"âš ï¸ ê²€ìƒ‰ ì‹¤íŒ¨ ({e}). ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©.")
            return self._get_sample_articles(flat_keywords)

    def _compare_perspectives_with_gemini(
        self, original_content: str, claims: list, articles: list
    ):
        if not gemini:
            raise Exception("Gemini APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        original_content = original_content[:config.MAX_CONTENT_LENGTH_SECOND_ANALYSIS]
        
        # ê¸°ì‚¬ ëª©ë¡ í…ìŠ¤íŠ¸í™”
        articles_text = "\n".join([
            f"- [{a['source']} ({a['country']})] {a['title']}: {a['snippet']}"
            for a in articles
        ])

        prompt = f"""
        ë‹¹ì‹ ì€ ê°ê´€ì ì¸ íŒ©íŠ¸ì²´ì»¤ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
        **ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.**

        [ê²€ì¦ ëŒ€ìƒ ì£¼ì¥ (ì‚¬ìš©ì ì„ íƒ)]
        {chr(10).join([f'- {c}' for c in claims])}

        [ìˆ˜ì§‘ëœ ê´€ë ¨ ê¸°ì‚¬/ìë£Œ]
        {articles_text}

        [ì§€ì‹œì‚¬í•­]
        1. ê° ì£¼ì¥ì— ëŒ€í•´ ìˆ˜ì§‘ëœ ê¸°ì‚¬ë“¤ì´ **ì§€ì§€(Supporting)**í•˜ëŠ”ì§€, **ë°˜ë°•(Opposing)**í•˜ëŠ”ì§€, ë˜ëŠ” **ì¤‘ë¦½/ê´€ë ¨ì—†ìŒ**ì¸ì§€ ë¶„ì„í•˜ì„¸ìš”.
        2. êµ­ê°€ë³„ ì–¸ë¡ ì˜ ì‹œê° ì°¨ì´ê°€ ìˆë‹¤ë©´ ì§€ì í•´ì£¼ì„¸ìš” (ì˜ˆ: ë¯¸êµ­ ì–¸ë¡ ì€ Aë¼ í•˜ì§€ë§Œ, ì¤‘êµ­ ì–¸ë¡ ì€ Bë¼ í•¨).
        3. ìµœì¢…ì ìœ¼ë¡œ ì´ ì£¼ì¥ì˜ ì‹ ë¢°ë„ë¥¼ 'ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ/íŒë‹¨ë¶ˆê°€'ë¡œ í‰ê°€í•˜ì„¸ìš”.

        [ì‘ë‹µ í˜•ì‹ (JSON)]
        {{
          "results": [
            {{
              "claim": "ì£¼ì¥ ë‚´ìš©",
              "verdict": "ëŒ€ì²´ë¡œ ì‚¬ì‹¤ / ë…¼ë€ ìˆìŒ / ê±°ì§“",
              "analysis_kr": "ë¶„ì„ ë‚´ìš© (í•œêµ­ì–´ ìƒì„¸ ì„¤ëª…)",
              "perspectives": [
                 {{"country": "US", "stance": "Supporting", "media": "CNN"}},
                 {{"country": "CN", "stance": "Opposing", "media": "Global Times"}}
              ]
            }}
          ]
        }}
        """
        
        try:
            response = gemini.generate_content(prompt)
            result_text = response.text.strip().replace('```json', '').replace('```', '').strip()
            return json.loads(result_text)
        except Exception as e:
            print(f"âŒ AI 2ì°¨ ë¶„ì„ ì‹¤íŒ¨: {e}")
            # ë¹ˆ ê²°ê³¼ ë°˜í™˜í•˜ì—¬ í”„ë¡ íŠ¸ì—”ë“œ ì—ëŸ¬ ë°©ì§€
            return {"results": []}

    # --- ìºì‹œ ë° ìœ í‹¸ë¦¬í‹° ---
    def _get_cache(self, url: str):
        if not db: return None
        try:
            cache_key = hashlib.md5(url.encode()).hexdigest()
            doc = db.collection('cache').document(cache_key).get()
            if doc.exists:
                print(f"âœ… ìºì‹œ íˆíŠ¸: {url[:30]}...")
                return doc.to_dict().get('result')
        except: pass
        return None

    def _set_cache(self, url: str, result):
        if not db: return
        try:
            cache_key = hashlib.md5(url.encode()).hexdigest()
            db.collection('cache').document(cache_key).set({
                'url': url, 'result': result, 'cached_at': datetime.now()
            })
        except: pass

    def _get_sample_articles(self, keywords: list):
        """ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„°"""
        k = keywords[0] if keywords else "ì´ìŠˆ"
        return [
            {'title': f'Global view on {k}', 'snippet': 'Western media perspective...', 'url': '#', 'source': 'CNN', 'country': 'US', 'credibility': 80},
            {'title': f'Alternative view on {k}', 'snippet': 'Eastern media perspective...', 'url': '#', 'source': 'Xinhua', 'country': 'CN', 'credibility': 60},
        ]